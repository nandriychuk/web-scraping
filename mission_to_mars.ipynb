{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-3972766eaf39>, line 73)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-3972766eaf39>\"\u001b[1;36m, line \u001b[1;32m73\u001b[0m\n\u001b[1;33m    mars_df=mars_df.to_html(index=False, col_space=100 header=False, border=1)##.replace('\\n', '')   , col_space=50\u001b[0m\n\u001b[1;37m                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def scrape_info():\n",
    "    browser = init_browser()\n",
    "    # # MARS NEWS\n",
    "    # Visit NASA Web site\n",
    "    url = 'https://mars.nasa.gov/news/'\n",
    "    browser.visit(url)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    \n",
    "    # Create a Beautiful Soup object\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    news_title = soup.find(\"div\", class_=\"content_title\").text\n",
    "    news_title\n",
    "    news_p = soup.find(\"div\", class_=\"article_teaser_body\").text\n",
    "    news_p\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    #MARS IMAGE\n",
    "    url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "    browser.visit(url)\n",
    "    html = browser.html\n",
    "    \n",
    "    # Create a Beautiful Soup object\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    article = soup.find('article', class_=\"carousel_item\")\n",
    "    style_link = article[\"style\"]\n",
    "    featured_image = style_link.split(\"('\", 1)[1].split(\"')\")[0]\n",
    "    featured_image_url = \"https://www.jpl.nasa.gov\" + featured_image\n",
    "    featured_image_url\n",
    "\n",
    "    \n",
    "\n",
    "    #MARS WEATHER\n",
    "    url = 'https://twitter.com/marswxreport?lang=en'\n",
    "    browser.visit(url)\n",
    "    html = browser.html\n",
    "    \n",
    "    # Create a Beautiful Soup object\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    mars_weather = soup.find_all('p',class_=\"TweetTextSize\")[1].text\n",
    "    mars_weather\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    #MARS INFO TABLE\n",
    "    url = 'https://space-facts.com/mars/'\n",
    "    browser.visit(url)\n",
    "    html = browser.html\n",
    "    \n",
    "    # Create a Beautiful Soup object\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    table = soup.find('table', id=\"tablepress-mars\")\n",
    "    table_rows = table.find_all('tr')\n",
    "\n",
    "    res = []\n",
    "    for tr in table_rows:\n",
    "        td = tr.find_all('td')\n",
    "        row = [tr.text.strip() for tr in td if tr.text.strip()] \n",
    "        if row:\n",
    "            res.append(row)\n",
    "\n",
    "    mars_df = pd.DataFrame(res)\n",
    "\n",
    "\n",
    "    mars_df=mars_df.to_html(index=False, col_space=100, header=False, border=1)##.replace('\\n', '')   , col_space=50\n",
    "    mars_df=mars_df.replace('\\n', '')\n",
    "    mars_df\n",
    "\n",
    "    \n",
    "\n",
    "    #Mars Hemispheres\n",
    "    url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    browser.visit(url)\n",
    "    html = browser.html\n",
    "    \n",
    "    # Create a Beautiful Soup object\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    links = browser.find_by_css('a.product-item h3')\n",
    "\n",
    "    hemisphere_image_urls = []\n",
    "    for i in range(len(links)):\n",
    "        url_dict = {}\n",
    "        url_dict[\"title\"] = browser.find_by_css('a.product-item h3')[i].text\n",
    "        browser.find_by_css('a.product-item h3')[i].click()\n",
    "\n",
    "        url_dict[\"img_url\"] = browser.find_link_by_text(\"Sample\").first[\"href\"]\n",
    "\n",
    "        hemisphere_image_urls.append(url_dict)\n",
    "        browser.back()\n",
    "    \n",
    "    # Store data in a dictionary\n",
    "    mars_data = {\n",
    "        \"new_title\": news_title,\n",
    "        \"news_paragraph\": news_p,\n",
    "        \"featured_img\": featured_image_url,\n",
    "        \"weater_tweeter\": mars_weather,\n",
    "        \"mars_facts\": mars_df,\n",
    "        \"hemispheres\": hemisphere_image_urls,\n",
    "    }\n",
    "\n",
    "    browser.quit()\n",
    "\n",
    "    # Return results\n",
    "    return mars_data\n",
    "\n",
    "    \n",
    "    \n",
    "scrape_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere Enhanced',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'},\n",
       " {'title': 'Schiaparelli Hemisphere Enhanced',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'},\n",
       " {'title': 'Syrtis Major Hemisphere Enhanced',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'},\n",
       " {'title': 'Valles Marineris Hemisphere Enhanced',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(hemisphere_image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
